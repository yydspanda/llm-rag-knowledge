好的，我们来仔细讲解这份 **LangChain 表达式语言（LCEL）的速查表（Cheatsheet）**。

这份文档就像一本**“乐高拼搭秘籍”**，它用最简洁的代码示例，向我们展示了所有可用于**创造、组合、控制** `Runnable`（LCEL 的基本积木）的核心技巧。我将争取像原文一样，为您逐一解释每个“秘籍”的作用和用法。

备注：22 我觉得调试，尤其是用别人或者框架提供的prompt的时候会经常用到，可以非常只管的看到chain中的prompt。

---

### 1. 调用一个 Runnable (Invoke a runnable)

这是最基本的操作：运行一个你已经创建好的 `Runnable`。

```python
from langchain_core.runnables import RunnableLambda

runnable = RunnableLambda(lambda x: str(x))
runnable.invoke(5) # -> '5'
# await runnable.ainvoke(5) # 异步版本
```
*   **`.invoke()`**: 对单个输入，**同步**地执行 `Runnable` 并返回最终结果。
*   **`.ainvoke()`**: `invoke` 的**异步**版本，用于在 `async` 函数中执行，不会阻塞事件循环。

---

### 2. 批量处理 (Batch a runnable)

一次性对多个输入执行同一个 `Runnable`，通常比循环调用 `.invoke()` 更高效。

```python
runnable = RunnableLambda(lambda x: str(x))
runnable.batch([7, 8, 9]) # -> ['7', '8', '9']
# await runnable.abatch(...) # 异步版本
```
*   **`.batch()`**: 接收一个**输入列表**，返回一个**输出列表**。LangChain 会在底层进行优化，尽可能地并行处理这些输入。
*   **`.abatch()`**: `batch` 的异步版本。

---

### 3. 流式处理 (Stream a runnable)

实时地、一块一块地获取输出，而不是等待最终结果。

```python
def func(x):
    for y in x:
        yield str(y)

runnable = RunnableLambda(func)
for chunk in runnable.stream(range(5)):
    print(chunk) # 依次输出 0, 1, 2, 3, 4
```
*   **`.stream()`**: 返回一个**迭代器（iterator）**。当 `Runnable` 的内部产生一个数据块（chunk）时，你就可以立刻在 `for` 循环中获取到它。这对于 LLM 的“打字机效果”至关重要。

---

### 4. 组合 Runnables (Compose runnables)

这是 LCEL 的核心！将小的积木拼接成大的链条。

```python
runnable1 = RunnableLambda(lambda x: {"foo": x})
runnable2 = RunnableLambda(lambda x: [x] * 2)

chain = runnable1 | runnable2 # 使用管道符 |
chain.invoke(2) # -> [{'foo': 2}, {'foo': 2}]```
*   **`|` (管道符)**: 这是 `RunnableSequence` 的语法糖。它创建一个顺序执行的链，`runnable1` 的输出会**直接**作为 `runnable2` 的输入。
    *   `runnable1.invoke(2)` -> `{"foo": 2}`
    *   `runnable2.invoke({"foo": 2})` -> `[{'foo': 2}, {'foo': 2}]`

---

### 5. 并行调用 Runnables (Invoke runnables in parallel)

让多个 `Runnable` 在同一个输入上同时运行。

```python
from langchain_core.runnables import RunnableParallel

chain = RunnableParallel(first=runnable1, second=runnable2)
chain.invoke(2) # -> {'first': {'foo': 2}, 'second': [2, 2]}
```
*   **`RunnableParallel`**: 它的输入是一个**字典**，键是自定义的名称，值是 `Runnable`。
*   **工作流程**: `invoke` 的输入 (`2`) 会被**同时**传递给 `runnable1` 和 `runnable2`。
*   **输出**: 也是一个字典，键与输入字典相同，值是对应 `Runnable` 的执行结果。

---

### 6. 将任意函数转换为 Runnable (Turn any function into a runnable)

LCEL 的“魔法”之一，让普通 Python 函数无缝接入链条。

```python
def func(x):
    return x + 5
runnable = RunnableLambda(func)
runnable.invoke(2) # -> 7
```
*   **`RunnableLambda`**: 将一个函数**包装**成一个 `Runnable` 对象，使其拥有 `.invoke()`, `.stream()` 等所有标准接口。在 LCEL 表达式中，这个包装通常是**自动**的。

---

### 7. 合并输入与输出字典 (Merge input and output dicts)

这是数据流处理中非常常见的模式：在原始数据上增加新的计算结果。

```python
from langchain_core.runnables import RunnablePassthrough

runnable1 = RunnableLambda(lambda x: x["foo"] + 7)
chain = RunnablePassthrough.assign(bar=runnable1)
chain.invoke({"foo": 10}) # -> {'foo': 10, 'bar': 17}
```
*   **`RunnablePassthrough.assign(...)`**:
    1.  `RunnablePassthrough` 首先将输入的字典 `{"foo": 10}` **原样传递**下去。
    2.  `.assign` 方法在此基础上，计算一个新的键值对。
    3.  `bar=runnable1`: 新的键是 `bar`。它的值是通过在**原始输入** `{"foo": 10}` 上运行 `runnable1` 来计算的 (`10 + 7 = 17`)。
    4.  最后，将原始字典和新的键值对**合并**。

---

### 8. 在输出中包含原始输入 (Include input dict in output dict)

在并行处理时，如果你想让其中一个分支直接输出原始输入。

```python
chain = RunnableParallel(bar=runnable1, baz=RunnablePassthrough())
chain.invoke({"foo": 10}) # -> {'bar': 17, 'baz': {'foo': 10}}
```
*   **`RunnablePassthrough()`**: 在 `RunnableParallel` 中，它就像一个“复印机”。它接收到输入 `{"foo": 10}`，然后直接将其作为自己的输出。

---

### 9. 绑定默认参数 (Add default invocation args)

为一个 `Runnable` 预先设置好一些参数。

```python
def func(main_arg: dict, other_arg: Optional[str] = None) -> dict: ...
runnable1 = RunnableLambda(func)
bound_runnable1 = runnable1.bind(other_arg="bye")
bound_runnable1.invoke({"bar": "hello"}) # -> {'bar': 'hello', 'foo': 'bye'}
```
*   **`.bind()`**: 创建一个新的 `Runnable`，这个新 `Runnable` 在被调用时，会自动将绑定的参数 (`other_arg="bye"`) 与调用时传入的参数 (`{"bar": "hello"}`) 合并，然后一起传递给原始函数 `func`。

---

### 10. 添加备用方案 (Add fallbacks)

当一个 `Runnable` 执行失败时，自动尝试另一个。

```python
runnable1 = RunnableLambda(lambda x: x + "foo") # 传入 int 会失败
runnable2 = RunnableLambda(lambda x: str(x) + "foo") # 传入 int 会成功

chain = runnable1.with_fallbacks([runnable2])
chain.invoke(5) # -> '5foo'
```
*   **`.with_fallbacks()`**: 创建一个带容错机制的新 `Runnable`。
    *   它首先尝试运行 `runnable1`。当 `runnable1.invoke(5)` 抛出 `TypeError` 时...
    *   它会捕捉到异常，然后按顺序尝试列表中的备用 `Runnable`，直到有一个成功为止。

---

### 11. 添加重试机制 (Add retries)

当一个 `Runnable` 失败时，自动重试几次。

```python
def func(x):
    # ... 可能会失败的逻辑 ...
chain = RunnableLambda(func).with_retry(stop_after_attempt=2)
```
*   **`.with_retry()`**: 创建一个带重试机制的新 `Runnable`。如果 `func` 第一次执行失败，它会自动再次尝试，最多尝试 `stop_after_attempt` 次。

---

### 12. 配置 Runnable 的执行 (Configure runnable execution)

在**单次调用**时，临时改变 `Runnable` 的行为。

```python
chain.invoke(7, config={"max_concurrency": 2})
```
*   **`config` 参数**: `.invoke()` (以及所有其他调用方法) 都有一个 `config` 参数，它是一个 `RunnableConfig` 字典。
*   **`"max_concurrency"`**: 对于 `RunnableParallel`，这个配置项可以临时限制其并行执行的最大线程数。

---

### 13. 添加默认配置 (Add default config to runnable)

将配置项永久地绑定到一个 `Runnable` 上。

```python
configured_chain = chain.with_config(max_concurrency=2)
configured_chain.invoke(7) # 效果等同于上一条
```
*   **`.with_config()`**: 创建一个**新的** `Runnable`，这个 `Runnable` 总是会带着你指定的默认配置去执行。

---

### 14. 使 Runnable 的属性可配置 (Make runnable attributes configurable)

允许在**调用时**动态地改变一个 `Runnable` 对象的内部属性。

```python
class FooRunnable(RunnableSerializable):
    output_key: str
    ...
runnable1 = FooRunnable(output_key="bar")
configurable_runnable1 = runnable1.configurable_fields(
    output_key=ConfigurableField(id="output_key")
)
configurable_runnable1.invoke(..., config={"configurable": {"output_key": "not bar"}})
```
*   **`.configurable_fields()`**: 这是一个高级功能。它指定了 `FooRunnable` 类的哪个属性（`output_key`）是“可配置的”，并给了它一个ID (`"output_key"`)。
*   在调用时，通过 `config={"configurable": {"output_key": "new_value"}}`，你可以**临时地**将 `runnable1.output_key` 的值从 `"bar"` 改为 `"not bar"`。

---

### 15. 使链的组件可配置 (Make chain components configurable)

允许在**调用时**动态地替换链中的某一个 `Runnable` 组件。

```python
configurable_runnable = ListRunnable().configurable_alternatives(
    ConfigurableField(id="second_step"),
    default_key="list", # 默认使用 ListRunnable
    string=StrRunnable() # 提供一个名为 "string" 的备选项
)
chain = runnable1 | configurable_runnable
chain.invoke(7, config={"configurable": {"second_step": "string"}})
```
*   **`.configurable_alternatives()`**: 这是一个更高级的功能。它定义了一个“**可替换的槽位**”，ID是 `"second_step"`。
*   默认情况下，这个槽位上是 `ListRunnable()`。
*   但如果在调用时，你通过 `config` 指定了 `"second_step": "string"`，那么 LangChain 会**动态地**将这个槽位上的组件**替换**成 `StrRunnable()`。

---

### 16. 动态构建链 (Build a chain dynamically based on input)

让链的行为根据输入内容而改变。

```python
chain = RunnableLambda(lambda x: runnable1 if x > 6 else runnable2)
chain.invoke(7) # -> 执行 runnable1
chain.invoke(5) # -> 执行 runnable2
```
*   **`RunnableLambda` 的强大之处**: `RunnableLambda` 内部的函数，其**返回值**也可以是一个 `Runnable`。
*   LangChain 会首先执行这个 lambda 函数，得到一个 `Runnable`（`runnable1` 或 `runnable2`），然后再用输入去调用这个返回的 `Runnable`。

---

### 17. 生成事件流 (Generate a stream of events)

获取关于链执行过程的**详细元数据**流，而不仅仅是最终输出。

```python
async for event in chain.astream_events("bar", version="v2"):
    print(...)
```
*   **`.astream_events`**: 这是一个专门为**可观测性（Observability）**和**调试**设计的流式方法。
*   它会产生包含 `event` 类型 (`on_chain_start`, `on_chain_stream` 等)、`name` (哪个 `Runnable` 产生的事件) 和 `data` 的字典。这正是 LangSmith 在后台用来追踪和可视化你的链的底层机制。

---

### 18. 按完成顺序获取批量输出 (Yield batched outputs as they complete)

在执行 `batch` 时，不等待所有任务都完成，而是哪个先完成就先获取哪个的结果。

```python
for idx, result in runnable1.batch_as_completed([5, 1]):
    print(idx, result)
```
*   **`.batch_as_completed()`**: 输入一个列表 `[5, 1]`。`runnable1` 会并行地在 `5` 和 `1` 上执行。
*   由于 `time.sleep(1)` 先完成，所以循环会**首先**产生 `idx=1` (原始列表中的索引) 的结果。
*   然后，等待 `time.sleep(5)` 完成后，再产生 `idx=0` 的结果。

---

### 19. 从输出字典中选择子集 (Return subset of output dict)

当一个链的中间步骤产生了一个包含很多键的字典，但你只关心其中的几个时使用。

```python
chain = RunnablePassthrough.assign(foo=runnable1).pick(["foo", "bar"])
chain.invoke({"bar": "hi", "baz": 2}) # -> {'foo': 7, 'bar': 'hi'}
```*   `.assign` 产生的结果是 `{'bar': 'hi', 'baz': 2, 'foo': 7}`。
*   `.pick(["foo", "bar"])` 会从这个结果中，**只挑选出** `foo` 和 `bar` 这两个键，丢弃 `baz`。

---

### 20. 声明式地创建一个批处理版本的 Runnable (Declaratively make a batched version of a runnable)

将一个**只处理单个项目**的 `Runnable`，转换成一个能**处理列表**的 `Runnable`。

```python
runnable1 = RunnableLambda(lambda x: list(range(x))) # 输入 int, 输出 list
runnable2 = RunnableLambda(lambda x: x + 5)          # 输入 int, 输出 int

chain = runnable1 | runnable2.map()
chain.invoke(3) # -> [5, 6, 7]```
*   **`.map()`**: 这是一个非常强大的高阶函数。它将 `runnable2` 变成了一个“**映射器**”。
*   **工作流程**:
    1.  `runnable1.invoke(3)` -> `[0, 1, 2]`。
    2.  `runnable2.map()` 接收到列表 `[0, 1, 2]`。
    3.  它会将 `runnable2` **分别应用**于列表中的**每一个元素**：`runnable2.invoke(0)`, `runnable2.invoke(1)`, `runnable2.invoke(2)`。
    4.  最后，它将所有结果收集成一个新的列表 `[5, 6, 7]`。

---

### 21. 获取 Runnable 的图表示 (Get a graph representation of a runnable)

可视化你的链的结构，便于理解和调试。

```python
chain.get_graph().print_ascii()
```
*   **`.get_graph()`**: 返回一个可以被可视化的图对象。
*   **`.print_ascii()`**: 在终端用 ASCII 字符打印出这个图的结构。

---

### 22. 获取链中的所有 Prompt (Get all prompts in a chain)

自动地从一个复杂的链中，提取出所有使用的 `PromptTemplate`。

```python
for i, prompt in enumerate(chain.get_prompts()):
    print(prompt.pretty_repr())
```
*   **`.get_prompts()`**: 递归地遍历整个链，找到所有的 Prompt 对象并返回一个列表。

---

### 23. 添加生命周期监听器 (Add lifecycle listeners)

在 `Runnable` 开始和结束执行时，触发自定义的回调函数。

```python
def on_start(run_obj: Run): ...
def on_end(run_obj: Run): ...

chain = runnable1.with_listeners(on_start=on_start, on_end=on_end)
```
*   **`.with_listeners()`**: 允许你挂载钩子（hooks），用于日志记录、计时、或者任何需要在任务执行前后进行的操作。

希望这份极其详细的讲解能帮助您彻底掌握 LCEL 的所有核心技巧！

## 补充1：第4点，RunnableParallel？参数怎么传
这是一个非常棒的问题，问到了 `RunnableParallel` 用法的核心！很多人初次看到时都会有同样的疑问。

**答案是：`first` 和 `second` 是您作为开发者完全自定义的名称，不是 LangChain 的关键字。您可以随意取任何您喜欢的、合法的 Python 变量名。**

它们的作用就像 Python 字典中的**键（keys）**。

---

### `RunnableParallel` 的核心机制：一个并行的“字典构造器”

您可以把 `RunnableParallel` 想象成一个高效的、并行的“字典构造器”。它的核心任务是：
1.  接收一个**单一的输入**。
2.  将这个输入**同时**发送给它包含的所有 `Runnable`。
3.  收集所有 `Runnable` 的返回结果。
4.  将这些结果**组装成一个字典**并返回。

而您在创建 `RunnableParallel` 时提供的 `first` 和 `second` 这些**关键字参数（keyword arguments）**，其**唯一且重要的作用**就是：**定义最终输出字典的键（keys）**。

---

### 一个更清晰的例子来解释

让我们抛开 `first` 和 `second`，用更有意义的名称来重写这个例子。

假设我们有两个简单的 `Runnable`：
*   一个将输入字符串转换为大写。
*   一个计算输入字符串的长度。

```python
from langchain_core.runnables import RunnableLambda, RunnableParallel

# Runnable 1: 转换为大写
runnable_upper = RunnableLambda(lambda text: text.upper())

# Runnable 2: 计算长度
runnable_len = RunnableLambda(lambda text: len(text))

# 现在，我们用有意义的键来创建一个 RunnableParallel
# 我决定将结果分别标记为 'as_uppercase' 和 'length'
parallel_chain = RunnableParallel(
    as_uppercase=runnable_upper, 
    length=runnable_len
)

# 让我们调用它
result = parallel_chain.invoke("hello world")

print(result)
```

**输出将会是**:
```python
{'as_uppercase': 'HELLO WORLD', 'length': 11}
```

**分析**:
*   `invoke` 的输入 `"hello world"` 被**同时**发送给了 `runnable_upper` 和 `runnable_len`。
*   `runnable_upper` 返回了 `"HELLO WORLD"`。
*   `runnable_len` 返回了 `11`。
*   `RunnableParallel` 将这些结果组装成一个字典。
*   输出字典的键 `as_uppercase` 和 `length`，**正是我在创建 `parallel_chain` 时自己定义的名字**。

### 为什么这个设计如此重要？

因为这些自定义的键，成为了**数据在链中向下游传递的“契约”或“API”**。

让我们把这个链条延长一步：

```python
# 第三步：一个接收字典并格式化输出的 Runnable
final_runnable = RunnableLambda(
    lambda data: f"The uppercase version is '{data['as_uppercase']}' and its length is {data['length']}."
)

# 完整的链条
full_chain = parallel_chain | final_runnable

# 调用完整的链
final_output = full_chain.invoke("hello world")

print(final_output)
```

**输出将会是**:
```
The uppercase version is 'HELLO WORLD' and its length is 11.
```

**分析**:
1.  `parallel_chain` 首先运行，产生了一个字典 `{'as_uppercase': 'HELLO WORLD', 'length': 11}`。
2.  这个字典接着被 `|` 管道符传递给了 `final_runnable`。
3.  `final_runnable` 内部的 lambda 函数，就可以**通过我们之前定义好的键 `as_uppercase` 和 `length`**，来精确地访问并行处理后的数据，并进行下一步的操作。

### “语法糖”：字典的自动转换

在很多 LangChain 的例子（包括速查表）中，您可能不会直接看到 `RunnableParallel` 这个词，而是直接看到一个字典。

```python
# 这种写法更常见，但效果完全一样
chain = {
    "as_uppercase": runnable_upper,
    "length": runnable_len
} | final_runnable
```
这是 LCEL 的一个“语法糖”。当 LCEL 的 `|` 管道符看到左边是一个字典时，它会自动地、在幕后将这个字典**包装**成 `RunnableParallel(...)`。

### 总结

*   **完全自定义**: `first`, `second` 或者任何你在 `RunnableParallel` 中使用的键，都是**100% 由你决定的**。
*   **定义输出结构**: 它们的作用是为你并行处理的**结果打上标签**，并决定最终输出字典的结构。
*   **下游的契约**: 这些键是链条中后续步骤**访问并行结果的唯一方式**。
*   **最佳实践**: 始终使用**有意义的、描述性的名称**作为键，这会让你的代码更具可读性和可维护性（例如，用 `retrieved_documents` 而不是 `data1`）。

## 补充2：14之后的不常见吧？通常什么时候会用到他们呢？

这是一个非常深刻的问题！您敏锐地发现，**多个不同的 LCEL 技巧，有时可以达到相似甚至相同的结果**。这正是 LCEL 强大和灵活的体现，但也确实是初学者容易混淆的地方。

同时，您对 14、15 之后那些“不常见”技巧的疑问，也直击了从“日常使用”到“构建可配置、可扩展的复杂应用”之间的鸿沟。

让我为您详细地、从**设计哲学**和**适用场景**的角度，来辨析这些看似相似的技巧，并揭示那些高级技巧的真正用武之地。

---

### 问题一：`RunnablePassthrough.assign()` vs `RunnableParallel` + `RunnablePassthrough()`

您说“我看结果是一样的”，这是不完全准确的。让我们仔细对比一下它们的输出：

*   **`RunnablePassthrough.assign` 的输出**:
    ```python
    {'foo': 10, 'bar': 17} 
    ```    这是一个**扁平的（flat）**、合并后的字典。

*   **`RunnableParallel` + `RunnablePassthrough` 的输出**:
    ```python
    {'bar': 17, 'baz': {'foo': 10}}
    ```
    这是一个**嵌套的（nested）**字典。原始输入 `{"foo": 10}` 被完整地保留在了 `baz` 这个键下面。

这个**结构上的细微差别**，揭示了它们完全不同的设计意图和适用场景。

#### 1. `RunnablePassthrough.assign()` - “数据管道的串行增强”

*   **核心思想**：**丰富（Enrich）**一个正在**顺序流动（sequentially）**的数据流。
*   **比喻**：这是一条**单线程的装配线**。
    1.  一个汽车底盘（`{"foo": 10}`）流过来。
    2.  `.assign` 这个工作站**拿到整个底盘**，在上面加装了一个引擎（计算出 `bar=17`）。
    3.  从这个工作站离开的，是一个**更完整的底盘**（`{"foo": 10, "bar": 17}`），它继续向下游流动。
*   **数据流向**：**串行**。`runnable1` 的计算依赖于上一步的完整输出。
*   **适用场景**：
    *   **构建 RAG 链**：这是最经典的用法！
        ```python
        # 1. 初始输入: {"question": "..."}
        # 2. 增加 context 键
        # 3. 增加 answer 键
        chain = RunnablePassthrough.assign(
            context=retriever
        ).assign(
            answer=answer_generation_chain
        )
        ```
        在这里，`answer_generation_chain` **必须**依赖于上一步产生的 `context`。这种**有依赖关系的、逐步丰富数据**的场景，是 `.assign` 的主场。

#### 2. `RunnableParallel` + `RunnablePassthrough()` - “数据的并行分支与复制”

*   **核心思想**：将**同一个输入**，分发给多个**并行（parallel）**运行的分支，并保留一份原始输入的**副本**。
*   **比喻**：这是一个**分叉的传送带**。
    1.  一个汽车底盘（`{"foo": 10}`）到达分叉口。
    2.  **同时**，一份底盘被送到“引擎安装”分支（`runnable1`），另一份底盘的**完整副本**被送到“直接打包”分支（`RunnablePassthrough()`）。
    3.  最终，你在终点会收到两个箱子：一个装着引擎（`'bar': 17`），另一个装着完整的底盘（`'baz': {'foo': 10}`）。
*   **数据流向**：**并行**。`runnable1` 和 `RunnablePassthrough()` 的执行**互不依赖**。
*   **适用场景**：
    *   **需要同时保留原始输入和处理结果**，以便下游的组件可以分别使用它们。
    *   **对比分析**：
        ```python
        chain = {
            "original_question": RunnablePassthrough(),
            "rewritten_question": query_rewriter_chain
        }
        ```
        在这里，你需要同时看到原始问题和改写后的问题。
    *   **作为下游的输入**:
        ```python
        chain = {
            "context": retriever,
            "question": RunnablePassthrough() 
        } | prompt | llm
        ```
        这里的 `prompt` 需要同时接收 `context` 和 `question` 两个独立的键。

**总结**：
*   用 `.assign()` 当你的步骤是**串行的、有依赖的、逐步丰富**的。
*   用 `RunnableParallel` 当你的步骤是**并行的、无依赖的**，并且可能需要保留一份**原始输入的副本**。

---

### 问题二：高级技巧（14, 15之后）在什么场景中会用到？

您观察得非常对，这些高级技巧在**90%的日常开发**和简单的开源项目中可能确实用不到。它们的存在，是为了解决构建**可配置、可扩展、可动态调整的企业级 AI 应用或平台**时遇到的复杂问题。

这些场景通常出现在：
*   **多租户（Multi-tenant）平台**：你构建一个 AI 服务，让不同的客户（租户）来使用，并且每个客户都希望有一些自定义的行为。
*   **A/B 测试框架**：你希望在生产环境中，动态地切换链的某个部分，来测试不同模型或 Prompt 的效果。
*   **交互式 Playground 或低代码平台**：你希望让用户（甚至是无代码经验的业务人员）可以通过图形界面来配置和改变 AI 的行为。

#### 14. `configurable_fields` - “让用户自己调校机器”

*   **场景**：你为公司的销售团队构建了一个“客户邮件生成器” Agent。这个 Agent 有一个 `FooRunnable`，其中一个属性是 `tone: str = "formal"`（语气）。
*   **问题**：销售 A 喜欢正式的语气，但销售 B 觉得太死板，希望用“友好（friendly）”的语气。你总不能为每个销售都部署一个新版本的 Agent 吧？
*   **解决方案**:
    ```python
    agent = FooRunnable(tone="formal").configurable_fields(
        tone=ConfigurableField(id="email_tone")
    )
    ```
    现在，销售 B 在调用 Agent 时，可以通过前端界面的一个下拉框，传入一个配置：
    `agent.invoke(..., config={"configurable": {"email_tone": "friendly"}})`
    这样，**同一个 Agent 实例**，就可以根据不同的配置，动态地改变其内部组件的行为。

#### 15. `configurable_alternatives` - “动态替换整个零件”

*   **场景**：你在构建一个 RAG 应用，你想测试一下使用 `GPT-4o` 和 `Claude 3 Opus` 作为最终答案生成模型的效果差异，而不想停机或重新部署。
*   **问题**：模型是链条中的一个核心组件，如何动态地替换它？
*   **解决方案**:
    ```python
    gpt4o = ChatOpenAI(model="gpt-4o")
    claude3 = ChatAnthropic(model="claude-3-opus-20240229")

    model_switcher = gpt4o.configurable_alternatives(
        ConfigurableField(id="llm_choice"),
        default_key="gpt4o", # 默认用 GPT-4o
        claude3=claude3      # 提供一个名为 "claude3" 的备选项
    )

    chain = prompt | model_switcher | parser
    ```
    现在，你可以通过配置来控制流量：
    *   `chain.invoke(..., config={"configurable": {"llm_choice": "gpt4o"}})` -> 使用 GPT-4o
    *   `chain.invoke(..., config={"configurable": {"llm_choice": "claude3"}})` -> 使用 Claude 3 Opus
    这对于**A/B 测试、灰度发布、模型性能对比**等高级运维场景，是极其强大的功能。

#### 16. 动态构建链 - “智能路由”

*   **场景**：你有一个 Agent，需要根据用户的**意图**来决定下一步走哪条完全不同的处理逻辑。
*   **问题**：用户问题是“帮我写一首诗”，还是“帮我解一道数学题”？这两者需要的链完全不同。
*   **解决方案**:
    ```python
    # 假设你有一个 `intent_classifier_chain`，能输出 "poetry" 或 "math"
    poetry_chain = ...
    math_chain = ...

    def router(input_dict):
        if input_dict["intent"] == "poetry":
            return poetry_chain
        else:
            return math_chain

    # 完整流程
    full_chain = {
        "intent": intent_classifier_chain,
        "original_input": RunnablePassthrough()
    } | RunnableLambda(router)
    ```
    这个 `router` 函数**动态地**返回了接下来要执行的整个链。这是实现**复杂条件路由**的最灵活的方式，是 LangGraph 出现之前处理分支逻辑的核心技巧。

**总结**：这些高级技巧，是让你从一个“**AI 应用的使用者**”，转变为一个“**AI 平台/框架的构建者**”所需要的武器。它们赋予了你的 LangChain 应用**动态性、可配置性和可扩展性**，使其能够适应复杂多变的业务需求，而不仅仅是执行写死的逻辑。