好的，我们来仔细讲解这份关于**如何在 LCEL 中运行自定义函数**的 LangChain 官方文档。

这份指南是掌握 LCEL **灵活性**和**可扩展性**的钥匙。它教我们如何将我们自己的、任意的 Python 代码，无缝地集成到强大的 LCEL 链条中，实现 LangChain 内置组件无法提供的**自定义逻辑**。

---

### 核心概念：为什么需要自定义函数？

虽然 LangChain 提供了丰富的内置组件（Prompts, LLMs, Parsers, Retrievers），但在真实的、复杂的应用中，你总会遇到一些需要**自定义处理逻辑**的场景：
*   **数据格式化**：将上一步的输出，转换成下一步所需的、一种非常特殊的格式。
*   **业务逻辑**：执行一些与你的特定业务相关的计算或判断。
*   **外部 API 调用**：调用一个 LangChain 没有内置支持的、你公司内部的 API。
*   **自定义解析**：编写一个能处理特殊输出格式（比如非标准 JSON）的解析器。

`RunnableLambda` 和 `@chain` 装饰器，就是 LangChain 为我们提供的、将这些自定义逻辑“**Runnable 化**”的官方工具。

**一个重要的前提**:
> 所有被用作 `Runnable` 的自定义函数，其函数签名**必须只接受一个参数**。如果你的函数需要多个参数，你需要写一个包装函数，让它接收一个字典，并在内部解包。

---

### 1. 显式创建：`RunnableLambda` 构造函数

这是最基础、最明确的方法。

**代码详解**:
```python
from langchain_core.runnable import RunnableLambda
from operator import itemgetter

def length_function(text): # 接收单个参数
    return len(text)

def _multiple_length_function(text1, text2): # 原始多参数函数
    return len(text1) * len(text2)

def multiple_length_function(_dict): # 包装函数，接收单个字典
    return _multiple_length_function(_dict["text1"], _dict["text2"])

chain = (
    {
        "a": itemgetter("foo") | RunnableLambda(length_function),
        "b": {"text1": itemgetter("foo"), "text2": itemgetter("bar")}
             | RunnableLambda(multiple_length_function),
    }
    | prompt
    | model
)
```
*   **`RunnableLambda(function_name)`**:
    *   这是一个**显式的包装器**。它接收一个普通的 Python 函数，并返回一个功能齐全的 `Runnable` 对象。
    *   这个新的 `Runnable` 对象拥有 `.invoke()`, `.stream()` 等所有标准接口。
*   **单参数 vs. 多参数**:
    *   `length_function` 天然符合“单参数”的要求，所以可以直接包装。
    *   `_multiple_length_function` 需要两个参数，不符合要求。因此，我们创建了一个**包装函数** `multiple_length_function`，它接收一个字典 `_dict`，然后在内部解包，调用原始函数。这个包装函数符合“单参数”的要求，可以被 `RunnableLambda` 包装。
*   **在链中使用**:
    *   `itemgetter("foo") | RunnableLambda(length_function)`: 数据流清晰。`itemgetter` 从初始输入中提取出 `"foo"` 的值（一个字符串），然后 `|` 管道符将其传递给 `RunnableLambda` 包装的 `length_function`。

---

### 2. 语法糖：`@chain` 装饰器

这是一种更简洁、更具声明性的方式，效果与 `RunnableLambda` 完全相同。

**代码详解**:
```python
from langchain_core.runnable import chain

@chain
def custom_chain(text):
    # 函数内部可以包含复杂的、多步骤的逻辑，
    # 甚至可以调用其他的链
    prompt_val1 = prompt1.invoke({"topic": text})
    output1 = ChatOpenAI().invoke(prompt_val1)
    # ...
    return chain2.invoke(...)
```
*   **`@chain`**: 这个装饰器会自动将它下面的函数 `custom_chain` 转换成一个 `RunnableLambda`。
*   **优点**:
    *   **封装复杂逻辑**: 它非常适合将一段**多步骤的、命令式的代码**，封装成一个单一的、可以在 LCEL 中被调用的“黑箱”组件。
    *   **可读性**: 代码看起来更像是普通的 Python 函数，而不是一个链的定义。
    *   **自动追踪**: 在 LangSmith 中，整个 `custom_chain` 会被视为一个独立的、可追踪的步骤，其内部的调用（如 `ChatOpenAI().invoke`）会作为其子步骤嵌套显示。

---

### 3. 自动转换 (Automatic Coercion)

这是 LCEL 最“魔法”、最便捷的特性。

**核心思想**:
> 当你在一个**已经存在的 `Runnable`** 后面，使用 `|` 管道符连接一个**普通的 Python 函数**时，LCEL 会**自动地**、在幕后将这个函数包装成 `RunnableLambda`。

**代码详解**:
```python
chain_with_coerced_function = prompt | model | (lambda x: x.content[:5])
```
*   **`(lambda x: x.content[:5])`**: 这是一个普通的 lambda 函数。
*   **为什么它能工作？**: 因为它前面 `prompt | model` 的结果，已经是一个 `Runnable` 对象了。当 `|` 操作符看到右边是一个函数时，它就会触发自动转换。
*   **优点**: 代码极其简洁。
*   **缺点**: 对于初学者可能不够明确，而且 IDE 可能无法很好地提供类型提示。

---

### 4. 传递“运行时配置” (`RunnableConfig`)

有时，你的自定义函数需要访问一些运行时的元数据，比如 `callbacks`, `tags` 等。

**代码详解**:
```python
from langchain_core.runnable import RunnableConfig

def parse_or_fix(text: str, config: RunnableConfig): # 签名中增加 config 参数
    # ...
    try:
        return json.loads(text)
    except Exception as e:
        # 在嵌套调用中，将 config 传递下去！
        text = fixing_chain.invoke({"input": text, "error": e}, config)
    # ...

# 调用时传入 config
RunnableLambda(parse_or_fix).invoke(
    "{foo: bar}", {"tags": ["my-tag"], "callbacks": [cb]}
)```
*   **函数签名**: 只要你的自定义函数的**第二个参数**被类型注解为 `RunnableConfig`，LangChain 在调用它时，就会**自动地**将当前的运行时配置注入到这个参数中。
*   **配置传播**: 最重要的实践是，如果你在函数内部又调用了其他的 `Runnable`（比如 `fixing_chain.invoke`），你**必须**将这个 `config` 对象**继续传递下去**。这样，整个调用链的追踪信息（tags, callbacks 等）才能保持完整。

---

### 5. 流式处理：使用生成器 (Generators)

这是一个高级但极其强大的技巧，它让你的自定义函数也能支持**流式输出**。

**核心思想**:
> 如果一个自定义函数是一个**生成器 (Generator)**（即函数体内使用了 `yield`），那么当它被用在链中时，它可以处理**输入的流**，并产生**输出的流**。

**代码详解**:
```python
from typing import Iterator

def split_into_list(input: Iterator[str]) -> Iterator[List[str]]:
    buffer = ""
    for chunk in input: # 接收一个输入的“块”流
        buffer += chunk
        while "," in buffer:
            comma_index = buffer.index(",")
            yield [buffer[:comma_index].strip()] # 产生一个输出的“块”
            buffer = buffer[comma_index + 1 :]
    yield [buffer.strip()] # 产生最后一个“块”

list_chain = str_chain | split_into_list
```
*   **输入是流**: 函数的输入 `input` 被注解为 `Iterator[str]`，它接收的是上一步 `str_chain` 流式输出的字符串块。
*   **输出也是流**: 函数使用 `yield` 来一块一块地产生输出。
*   **工作原理**: 这个函数就像一个“**流式解析器**”。它不断地从上游接收字符流，存入一个 `buffer`。每当它在 `buffer` 中找到一个完整的片段（以逗号为界），它就立刻 `yield` 这个片段，然后继续处理剩下的 `buffer`。
*   **效果**: 这使得整个 `list_chain` 从头到尾都是流式的。用户可以实时地看到解析出的动物列表，而不是等所有动物都生成完毕才一次性看到。

**异步版本**: 逻辑完全一样，只是函数签名和循环需要使用 `async` 和 `await` 关键字。

### 总结

LangChain 提供了多种方式将你的自定义逻辑融入 LCEL，以适应不同的需求和编码风格：
*   **`RunnableLambda`**: 最基础、最明确的包装器。
*   **`@chain`**: 封装复杂、多步逻辑的优雅语法糖。
*   **自动转换**: 在 `|` 管道中，最简洁、最“魔法”的方式。
*   **`RunnableConfig`**: 让你的函数能够感知和传播运行时的上下文。
*   **生成器函数**: 实现自定义**流式处理**的终极武器。

掌握了这些技巧，你就拥有了无限扩展 LangChain 能力的钥匙，可以构建出任何你想要的、高度定制化的 AI 应用。