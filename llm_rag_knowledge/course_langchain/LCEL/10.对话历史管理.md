好的，我们来仔细讲解这份关于**如何为 Runnable 添加消息历史（即“记忆”）**的 LangChain 官方文档。

这份指南极其重要，因为它标志着 LangChain 架构思想的一次重大演进。它明确地告诉开发者：**对于需要“记忆”的新应用，我们推荐使用 LangGraph 的持久化功能，而不是旧的 `RunnableWithMessageHistory`。**

我们将深入探讨**为什么**会有这个转变，以及 LangGraph 是如何以一种更强大、更灵活的方式来实现“记忆”的。

---

### 核心问题：为什么需要“记忆”？以及旧方法的局限

**为什么需要记忆？**
一个没有记忆的聊天机器人是“失忆”的。你上一秒告诉它你叫 Bob，下一秒问它你叫什么，它会回答“我不知道”。“记忆”或“消息历史”是构建任何连贯的、多轮对话应用的**基本前提**。

**旧方法 `RunnableWithMessageHistory` 的局限**:
在 LangChain v0.2.0 之前，`RunnableWithMessageHistory` 是实现记忆的标准方式。它做得不错，但存在一些根本性的局限：

1.  **状态单一**: 它被设计为**只管理消息历史** (`List[BaseMessage]`)。如果你的链条需要记住其他东西（比如用户选择的语言、用户的ID、之前检索到的文档），它就无能为力了。
2.  **“黑箱”操作**: 它在幕后自动地加载和保存历史，虽然方便，但也让开发者对状态的管理和修改缺乏精细的控制。
3.  **扩展性差**: 很难将它无缝地集成到更复杂的、带有多步、分支或循环的 Agentic 工作流中。

**LangGraph 的出现，就是为了解决这些问题。**

---

### 新范式：使用 LangGraph 持久化来实现“广义记忆”

LangGraph 引入了一种更强大、更通用的“记忆”概念，我们称之为**持久化状态（Persistent State）**。

**核心思想**:
> 我们不再仅仅是保存“消息历史”，而是可以**保存和管理整个应用在任意时间点的完整状态（State）**。这个状态可以是任何你定义的数据结构，消息历史只是其中的一部分。

这份指南的核心，就是教我们如何将**任何一个普通的 LangChain Runnable**，通过一个**极简的 LangGraph 应用**来包装，从而轻松地为其赋予这种强大的、可定制的“记忆”能力。

---

### 示例一：为最简单的 Runnable（Chat Model）添加记忆

这是入门的第一步，展示了最核心的模式。

**步骤 1: 定义图的状态 (Define the Graph State)**

```python
from langgraph.graph import MessagesState

workflow = StateGraph(state_schema=MessagesState)
```
*   **`MessagesState`**: 这是 LangGraph 内置的一个 `TypedDict`，专门用于存储消息列表。它的定义大致是 `{"messages": Annotated[Sequence[BaseMessage], add_messages]}`。
*   **`StateGraph(...)`**: 我们声明，我们这个图的**全局状态**，必须符合 `MessagesState` 这个蓝图。

**步骤 2: 定义图的节点 (Define the Node)**
```python
def call_model(state: MessagesState):
    response = llm.invoke(state["messages"])
    return {"messages": response} # LangGraph 会自动用 add_messages 来追加

workflow.add_node("model", call_model)
```
*   **`call_model(state: MessagesState)`**: 我们的图只有一个工作站。这个工作站接收当前的**全局状态** `state`，从中取出 `messages`，调用 `llm`，然后返回一个**状态更新**的字典。

**步骤 3: 定义图的流程 (Define the Edges)**
```python
workflow.add_edge(START, "model")
```
*   这是一个最简单的流程：**开工 (`START`) -> 直接去 `model` 工作站**。
*   **等等，没有 `END`？** 在这种简单的单节点图中，如果一个节点执行完后，没有边指向下一个节点，流程就会**自动结束**。

**步骤 4: 编译并添加“记忆引擎” (Compile with a Checkpointer)**
```python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
app = workflow.compile(checkpointer=memory)
```
*   **`MemorySaver()`**: 我们选择了一个最简单的“记忆引擎”，它将状态保存在内存中。
*   **`checkpointer=memory`**: **这是赋予“记忆”的关键！** 通过在编译时传入一个 `checkpointer`，我们告诉 LangGraph：“请在每次调用之间，自动地、根据 `thread_id`，为我保存和加载这个图的完整状态。”

**如何使用**:
```python
config = {"configurable": {"thread_id": "abc123"}} # 像游戏存档槽位

# 第一次调用
app.invoke({"messages": [HumanMessage("Hi! I'm Bob.")]}, config)

# 第二次调用 (只传新消息)
app.invoke({"messages": [HumanMessage("What's my name?")]}, config)
```
*   **`thread_id`**: 唯一标识一个对话会话。
*   **工作流程**:
    1.  第二次调用时，`checkpointer` 根据 `"abc123"` **自动加载**了第一次对话的历史（一问一答）。
    2.  `call_model` 节点接收到的 `state`，其 `messages` 字段**已经包含了**历史记录和新问题。
    3.  `llm` 看到了完整的上下文，因此能正确回答“Your name is Bob”。
    4.  调用结束后，`checkpointer` 将**更新后的、更长的历史**再次保存到 `"abc123"` 这个槽位里。

---

### 示例二：为更复杂的 Runnable（带 Prompt 的链）添加记忆

这个例子展示了 LangGraph 状态管理的**真正威力**：我们可以记住**任何我们想要的东西**。

**问题**: 我们的新 `runnable = prompt | llm` 需要一个包含 `messages` 和 `language` 两个键的字典作为输入。我们如何同时记住这两样东西？

**步骤 1: 定义一个自定义的、更丰富的状态**

```python
class State(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    language: str # 我们增加了一个新的字段来记住语言！
```
*   **`add_messages`**: 这是一个特殊的 LangGraph 函数，它告诉 `StateGraph`，当更新 `messages` 字段时，应该执行**追加（append）**操作，而不是覆盖。
*   **`language: str`**: 对于普通的 `str` 类型，默认的更新行为是**覆盖（overwrite）**。这正是我们想要的。

**步骤 2: 其余部分几乎完全一样**
我们只是把 `StateGraph(state_schema=MessagesState)` 换成了 `StateGraph(state_schema=State)`，并确保我们的 `call_model` 函数现在接收 `State` 类型的状态。

**如何使用**:
```python
input_dict = {
    "messages": [HumanMessage("Hi, I'm Bob.")],
    "language": "Spanish",
}
output = app.invoke(input_dict, config)
```
*   **第一次调用**: 我们传入了初始的消息和语言 `"Spanish"`。`checkpointer` 将 `{"messages": [...], "language": "Spanish"}` 这个完整的状态保存了下来。
*   **后续调用**: 即使后续只传入 `{"messages": [HumanMessage("How are you?")]}`，`checkpointer` 也会**自动加载**出 `"language": "Spanish"`，确保 `prompt` 能正确地格式化，LLM 会继续用西班牙语回答。

---

### 管理消息历史 (Managing Message History)

LangGraph 提供了直接与 `checkpointer` 交互的方法，让我们能像操作数据库一样，读取和修改会话状态。

*   **`app.get_state(config)`**: 读取指定 `thread_id` 的当前完整状态。
*   **`app.update_state(config, {"messages": [...]})`**: **修改**指定 `thread_id` 的状态。你可以用它来手动添加、删除消息，或者改变 `language` 等任何状态字段。

### 总结

这份指南的核心是向我们展示了 LangGraph 如何**从根本上超越**了旧的记忆模式：

1.  **广义状态管理**: LangGraph 管理的是**整个应用的、可任意定制的 state**，而不仅仅是消息历史。你可以把任何你需要记住的东西（用户偏好、会话ID、中间结果）都放进状态里。
2.  **清晰的逻辑**: 状态的定义（`TypedDict`）、节点的逻辑（`def call_model(...)`）和流程的控制（`.add_edge(...)`）被**完全解耦**，代码清晰且易于维护。
3.  **无缝集成**: 任何一个 `Runnable`，无论它多么简单或复杂，都可以通过一个极简的 LangGraph “包装器”，被赋予强大的、持久化的“记忆”能力。
4.  **精细化控制**: 通过 `.get_state` 和 `.update_state`，我们获得了对会话状态**完全的、程序化的控制权**。

这标志着 LangChain 的记忆管理，从一个“内置黑箱”，演进为了一个**透明、灵活、可扩展的“状态管理框架”**。

## 补充：怎么获取状态里的值

```python
state = app.get_state(config).values

print(f"Language: {state['language']}")
for message in state["messages"]:
    message.pretty_print()
```