[参考链接](https://python.langchain.com/docs/how_to/routing/)

好的，我们来仔细讲解这份关于**如何在子链之间进行路由（Routing）**的 LangChain 官方文档。

这份指南是构建**非确定性（non-deterministic）**链条的关键。所谓“非确定性”，指的是链条的**执行路径不是固定的**，而是根据上一步的输出**动态地决定**下一步应该走哪条路。这使得我们的 AI 应用能够根据用户的不同意图，调用不同的“专家”或执行不同的逻辑，变得更加智能和灵活。

---

### 核心问题：为什么需要路由？

一个简单的链条就像一条笔直的高速公路，所有车辆（输入）都走同一条路。但现实世界充满了岔路口。

*   用户问的是关于“LangChain”的问题，还是“Anthropic”的问题？我们希望调用不同的“专家”Prompt 来回答。
*   用户是在提问，还是在闲聊？我们可能需要路由到 RAG 链或一个纯聊天链。
*   用户的提问属于“物理”领域还是“数学”领域？我们希望用不同的“人设”和知识来回答。

路由，就是构建这些**智能“岔路口”**的机制。

---

### 示例准备 (Example Setup)

为了演示路由，文档首先准备了几个核心组件：
1.  **一个“分类器”链 (`chain`)**:
    *   它的唯一任务是接收用户问题，然后判断这个问题属于 `LangChain`, `Anthropic`, 还是 `Other` 这三个类别之一。这是一个简单的 LLM 调用。
2.  **三个“专家”子链**:
    *   `langchain_chain`: 一个带有“我是 Harrison Chase 专家”人设的 Prompt 链。
    *   `anthropic_chain`: 一个带有“我是 Dario Amodei 专家”人设的 Prompt 链。
    *   `general_chain`: 一个通用的、没有特殊人设的 Prompt 链。

我们的目标就是：构建一个主链条，它能先用“分类器”判断问题类别，然后智能地将问题**路由**给正确的“专家”子链。

---

### 方案一：使用自定义函数（推荐）

这是 LangChain **官方推荐**的、最灵活、最Pythonic 的路由方式。

**核心思想**:
> 我们用一个普通的 Python 函数来**显式地编写路由逻辑**。这个函数接收上一步（分类器）的输出，然后**返回**接下来应该被执行的那个 `Runnable`（专家子链）。

#### 代码详解

**1. 编写路由函数**
```python
def route(info):
    # info 是一个字典，包含了上一步的所有输出
    # 在这里，它会是 {"topic": "Anthropic", "question": "how do I use Anthropic?"}
    if "anthropic" in info["topic"].lower():
        return anthropic_chain # 返回一个 Runnable 对象
    elif "langchain" in info["topic"].lower():
        return langchain_chain # 返回一个 Runnable 对象
    else:
        return general_chain   # 返回一个 Runnable 对象
```
*   这个函数就是我们的“**智能交换机**”。它内部的 `if/elif/else` 逻辑非常清晰。
*   最关键的是，它的**返回值**不是一个字符串或数字，而是一个**完整的、可执行的 `Runnable` 对象**。

**2. 构建完整的主链**
```python
from langchain_core.runnables import RunnableLambda

full_chain = {"topic": chain, "question": lambda x: x["question"]} | RunnableLambda(
    route
)
```
*   **第一部分: `{"topic": ..., "question": ...}`**
    *   这是一个 `RunnableParallel`，负责并行地准备好 `route` 函数所需的所有输入。
    *   `"topic": chain`: 运行“分类器”链，得到问题的类别（如 "Anthropic"）。
    *   `"question": lambda x: x["question"]`: 这里使用了一个 lambda 函数（也可以用 `RunnablePassthrough` 或 `itemgetter`），它的作用是**“直通”**原始的用户问题。
    *   这一步的输出是一个字典，例如 `{"topic": "Anthropic", "question": "how do I use Anthropic?"}`。
*   **第二部分: `| RunnableLambda(route)`**
    *   **LCEL 的魔法**: 当一个 `RunnableLambda` 的函数**返回另一个 `Runnable`** 时，LCEL 运行时会自动地**执行那个被返回的 `Runnable`**。
    *   **工作流程**:
        1.  `route` 函数被调用，接收到上一步的字典。
        2.  `route` 函数根据 `"topic"` 的值，返回了 `anthropic_chain` 这个 `Runnable` 对象。
        3.  LCEL 运行时拿到 `anthropic_chain`，然后会用 `route` 函数的**原始输入**（即那个包含 `topic` 和 `question` 的字典）去 `.invoke()` 这个 `anthropic_chain`。
        4.  `anthropic_chain` 的 Prompt 需要 `{question}`，它成功地从输入字典中找到了这个键，并最终完成了调用。

---

### 方案二：使用 `RunnableBranch` (旧版/不推荐)

这是一种更具“声明性”的、旧式的路由方法。官方现在推荐使用自定义函数，因为它更灵活、更易读。

**核心思想**:
> `RunnableBranch` 让你用一系列 `(条件, Runnable)` 的元组来定义路由规则。

#### 代码详解
```python
from langchain_core.runnables import RunnableBranch

branch = RunnableBranch(
    # 元组1: (条件函数, 如果为真则执行的Runnable)
    (lambda x: "anthropic" in x["topic"].lower(), anthropic_chain),
    # 元组2
    (lambda x: "langchain" in x["topic"].lower(), langchain_chain),
    # 默认 Runnable (如果以上条件都不满足)
    general_chain,
)

full_chain = {"topic": chain, "question": lambda x: x["question"]} | branch
```
*   **工作流程**:
    1.  `branch` 接收到上一步传来的字典 `{"topic": "Anthropic", ...}`。
    2.  它会**按顺序**地检查每一个条件：
        *   **检查条件1**: `lambda x: "anthropic" in x["topic"].lower()`，传入字典，返回 `True`。
        *   **匹配成功！** `branch` 会立刻执行与这个条件配对的 `anthropic_chain`，并**忽略**所有后续的条件。
        *   如果条件1返回 `False`，它会继续检查条件2，以此类推。
        *   如果所有条件都为 `False`，它会执行最后那个**默认的 `Runnable`** (`general_chain`)。

---

### 方案三：基于语义相似度的路由 (最高级)

这是路由思想的一个非常强大和智能的应用。

**核心思想**:
> 我们不再依赖一个 LLM 分类器来做硬性分类（"LangChain" vs "Anthropic"）。而是，我们将**用户的查询**与**每个“专家”Prompt 的描述**进行**向量嵌入相似度**计算，然后选择最相似的那个“专家”Prompt 来执行。

#### 代码详解
```python
# 1. 定义“专家”Prompt 模板
physics_template = "You are a very smart physics professor..."
math_template = "You are a very good mathematician..."

# 2. 将这些模板本身进行向量化
embeddings = OpenAIEmbeddings()
prompt_templates = [physics_template, math_template]
prompt_embeddings = embeddings.embed_documents(prompt_templates)

# 3. 编写一个基于向量相似度的路由函数
def prompt_router(input):
    # 将用户查询也进行向量化
    query_embedding = embeddings.embed_query(input["query"])
    # 计算用户查询与所有模板描述的余弦相似度
    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]
    # 选择最相似的那个模板
    most_similar = prompt_templates[similarity.argmax()]
    # 动态地从这个模板字符串创建一个 PromptTemplate 对象并返回
    return PromptTemplate.from_template(most_similar)

# 4. 构建链
chain = (
    {"query": RunnablePassthrough()}
    | RunnableLambda(prompt_router) # 动态选择 Prompt
    | ChatAnthropic(...)
    | StrOutputParser()
)```*   **工作流程**:
    *   当用户输入 `"What's a black hole"` 时，`prompt_router` 会发现这个问题在语义上与 `physics_template` 的描述更接近。
    *   因此，`prompt_router` 会**动态地**返回一个基于 `physics_template` 的 `PromptTemplate` 对象。
    *   下游的 `ChatAnthropic` 就会以一个“物理学教授”的身份来回答问题。
*   **价值**: 这种方法极其灵活和可扩展。如果你想增加一个新的“化学专家”，你只需要在 `prompt_templates` 列表中增加一个新的模板字符串即可，**无需修改任何路由逻辑**！

### 总结

| 路由方法 | 核心思想 | 优点 | 缺点 | 推荐度 |
| :--- | :--- | :--- | :--- | :--- |
| **自定义函数** | 用 Python `if/else` **返回**不同的 `Runnable` | **最灵活**，最Pythonic，逻辑清晰 | 需要自己编写函数 | **最高** |
| **`RunnableBranch`** | 用 `(条件, Runnable)` 元组列表来声明 | 声明性强，代码可能更紧凑 | 灵活性不如函数，官方已不主推 | 中 |
| **语义相似度** | 用向量相似度**动态选择**`PromptTemplate` | **极度灵活**，易于扩展新路由 | 需要嵌入模型，有额外成本和延迟 | **最高 (用于Prompt选择)** |

掌握了路由，你的 LCEL 应用就从“单行道”进化到了拥有智能交通系统的“城市路网”，能够根据不同的“交通状况”（用户输入），将任务高效地引导至最合适的处理中心。