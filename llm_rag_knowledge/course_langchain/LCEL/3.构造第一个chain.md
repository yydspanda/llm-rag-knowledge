好的，我们来仔细讲解这份关于**如何链接（Chain）Runnables** 的 LangChain 官方文档。

这份指南是 LangChain 表达式语言 (LCEL) 的核心实践教程。它向我们展示了 LCEL 最基本、也是最强大的特性：如何像**拼接乐高积木**一样，将独立的 AI 组件（`Runnable`）连接起来，构建成一个**顺序执行**的、功能更强大的**工作流（`RunnableSequence`）**。

---

### 核心概念：什么是“链接”（Chaining）？

在 LCEL 中，“链接”或“串联”指的是创建一个**序列（Sequence）**，其中：

> **前一个组件的输出，会直接成为下一个组件的输入。**

这个过程可以通过极其简洁的**管道符 `|`** 来实现。

**比喻：一条汽车装配线**
1.  **原材料**：一块钢板（用户的输入）。
2.  **第一道工序 (`prompt`)**：将钢板冲压成车身框架（将输入格式化成 Prompt）。
3.  **第二道工序 (`model`)**：给车身框架喷漆（LLM 处理 Prompt，生成响应）。
4.  **第三道工序 (`parser`)**：给喷好漆的车身打蜡抛光（将模型的输出解析成干净的字符串）。

`prompt | model | parser` 这行代码，就**声明**了这条装配线的**工作流程**。

---

### 1. 基础链接：`prompt | model | parser`

这是所有 LCEL 应用中最经典、最常见的模式。

#### 代码详解

**步骤 1: 准备组件**
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# 组件1: 提示模板 (Runnable)
prompt = ChatPromptTemplate.from_template("tell me a joke about {topic}")

# 组件2: 聊天模型 (Runnable)
model = ChatOpenAI(model="gpt-3.5-turbo")

# 组件3: 输出解析器 (Runnable)
output_parser = StrOutputParser()
```*   这里的每一个组件（`prompt`, `model`, `parser`）都是一个独立的 `Runnable` 对象，它们都遵循统一的接口。

**步骤 2: 使用 `|` 链接组件**
```python
chain = prompt | model | output_parser
```
*   这行代码创建了一个新的、更强大的 `Runnable`，它是一个 `RunnableSequence`。
*   它**声明**了数据流动的顺序。

**步骤 3: 调用链**
```python
chain.invoke({"topic": "bears"})
```
*   **幕后发生的事情 (数据流追踪)**:
    1.  `invoke` 的输入 `{"topic": "bears"}` 首先被发送给 `prompt`。
    2.  `prompt` 执行，将字典输入格式化成一个 `PromptValue` 对象，其内容大致是 `[HumanMessage(content="tell me a joke about bears")]`。
    3.  这个 `PromptValue` 对象被传递给 `model`。
    4.  `model` 接收到消息列表，调用 OpenAI API，返回一个 `AIMessage` 对象，其 `.content` 属性是笑话文本。
    5.  这个 `AIMessage` 对象被传递给 `output_parser`。
    6.  `StrOutputParser` 的作用就是从 `AIMessage` 中提取出 `.content` 字符串。
    7.  最终，`chain` 返回一个干净的字符串作为结果。

**链接的优势**:
*   **流式输出 (Streaming)**: 如果你调用 `chain.stream(...)`，当 `model` 开始生成第一个词时，这个词就会立刻通过 `output_parser` 并被 `yield` 出来，你不需要等待整个笑话都生成完毕。
*   **可观测性 (Observability)**: 在 LangSmith 中，你会清晰地看到这次调用包含了三个独立的步骤：`ChatPromptTemplate`, `ChatOpenAI`, `StrOutputParser`，以及它们各自的输入和输出。

---

### 2. 进阶链接：处理输入/输出不匹配的问题 (Coercion)

现在，我们想把上面那个“笑话生成链”（`chain`）作为**新链条的第一步**。

**新目标**：创建一个链，它能先生成一个笑话，然后**评价**这个笑话是否好笑。

**遇到的问题**:
*   我们的 `chain` 的输出是一个**字符串**（笑话本身）。
*   而下一步的 `analysis_prompt`（`"is this a funny joke? {joke}"`）需要一个**字典**作为输入，即 `{"joke": "..."}`。

直接用 `chain | analysis_prompt` 会因为**输入/输出类型不匹配而失败**。我们需要一个“**适配器**”来转换数据格式。

#### 解决方案 A: 使用字典（自动转换为 `RunnableParallel`）

这是最常见、最优雅的解决方案。

```python
analysis_prompt = ChatPromptTemplate.from_template("is this a funny joke? {joke}")

composed_chain = {"joke": chain} | analysis_prompt | model | StrOutputParser()

composed_chain.invoke({"topic": "bears"})
```
*   **`{"joke": chain}` 的魔法**:
    1.  这是一个字典，LCEL 会自动将其转换为 `RunnableParallel`。
    2.  当 `composed_chain.invoke({"topic": "bears"})` 被调用时，`{"topic": "bears"}` 这个输入会被发送给 `RunnableParallel`。
    3.  `RunnableParallel` 会执行 `chain.invoke({"topic": "bears"})`，得到笑话字符串。
    4.  然后，它将这个结果，作为 `joke` 这个键的值，**组装成一个新的字典**：`{"joke": "Why don't bears wear shoes? ..."}`。
*   这个新组装的字典，其格式**完美地匹配**了 `analysis_prompt` 所需的输入 `{joke}`。
*   这样，数据流就成功地从一个字符串，转换成了一个符合下一步要求的字典，整个链条得以顺利执行。

#### 解决方案 B: 使用 Lambda 函数（自动转换为 `RunnableLambda`）

如果你觉得字典的写法不够直观，也可以用一个明确的函数来做这个“适配器”。

```python
composed_chain_with_lambda = (
    chain
    | (lambda input_string: {"joke": input_string})
    | analysis_prompt
    | model
    | StrOutputParser()
)
```
*   **`(lambda input_string: {"joke": input_string})`**:
    *   这是一个匿名的 Python 函数。
    *   LCEL 会自动将其包装成 `RunnableLambda`。
    *   它的作用非常明确：接收上一步 `chain` 输出的字符串 (`input_string`)，然后把它包装成一个字典 `{"joke": ...}`。
    *   它的效果与 `{"joke": chain}` 完全相同，只是写法更明确。

---

### 3. 另一种语法：`.pipe()` 方法

如果你（或你的团队）不喜欢 `|` 这种操作符重载的语法，觉得它不够明确，LangChain 提供了功能完全相同的 `.pipe()` 方法。

```python
composed_chain_with_pipe = (
    RunnableParallel({"joke": chain})
    .pipe(analysis_prompt)
    .pipe(model)
    .pipe(StrOutputParser())
)
```
*   **`.pipe(another_runnable)`**: 等同于 `| another_runnable`。
*   **优点**: 语法更像传统的函数式编程，可读性可能对某些开发者更友好。
*   **`.pipe()` 的变体**: `pipe` 方法还可以一次性接收多个 `Runnable`，它会自动将它们串联起来。
    ```python
    .pipe(analysis_prompt, model, StrOutputParser())
    ```

### 总结

这份指南的核心是教会我们 LCEL 最基础的**顺序组合**能力：
1.  **`|` (或 `.pipe()`)** 是将 `Runnable` 组件**串联**起来的核心操作。
2.  当链接的组件之间**输入/输出格式不匹配**时，我们需要使用“**适配器**”来进行转换。
3.  最常用的适配器是**字典**（会自动变成 `RunnableParallel`）和**函数**（会自动变成 `RunnableLambda`），它们能帮助我们轻松地重塑数据流，以满足下一个组件的需求。

掌握了这些基础的链接技巧，你就掌握了构建几乎任何复杂度的线性或简单分支的 AI 应用的能力。