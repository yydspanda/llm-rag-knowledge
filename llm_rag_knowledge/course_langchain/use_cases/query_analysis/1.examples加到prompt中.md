### 核心思想：为什么需要添加示例？

当我们面对的查询分析任务变得复杂时，单靠指令（System Prompt）可能不足以让大语言模型（LLM）在所有情况下都准确理解我们想要的输出格式。为了提升性能，我们可以向提示中添加一些“输入-输出”的范例，这就像是给模型几个“标准答案”作为参考，从而更好地引导它。

这篇文档的目标是构建一个 LangChain YouTube 视频的查询分析器，并演示如何通过添加示例来优化它。

---

### 1. 初始设置 (Setup)

这部分是准备工作，确保环境和代码结构都已就绪。

#### 1.1. 定义查询结构 (Query schema)

我们首先需要定义希望模型输出的数据结构。这里使用 Pydantic 模型来定义。为了让任务更有趣，我们不仅要有一个主查询 `query`，还要有一个 `sub_queries` 字段，用于将原始问题分解成更具体、更细分的子问题。

```python
# 原文代码
from typing import List, Optional
from pydantic import BaseModel, Field

# 这是对 sub_queries 字段的详细描述，会作为指令的一部分给到模型
sub_queries_description = """\
If the original question contains multiple distinct sub-questions, \
or if there are more generic questions that would be helpful to answer in \
order to answer the original question, write a list of all relevant sub-questions. \
Make sure this list is comprehensive and covers all parts of the original question. \
It's ok if there's redundancy in the sub-questions. \
Make sure the sub-questions are as narrowly focused as possible."""

class Search(BaseModel):
    """在一个关于某个软件库的教程视频数据库中进行搜索。"""

    query: str = Field(
        ...,
        description="应用于视频文本记录的主要相似性搜索查询。",
    )
    sub_queries: List[str] = Field(
        default_factory=list, description=sub_queries_description
    )
    publish_year: Optional[int] = Field(None, description="视频发布的年份")
```

*   **讲解**:
    *   我们定义了一个名为 `Search` 的 Pydantic 模型。
    *   `query`: 字符串类型，是用于向量搜索的主要查询。
    *   `sub_queries`: 一个字符串列表。它的描述 (`sub_queries_description`) 非常详细，指导模型如何将一个复杂问题拆解成多个更小、更集中的子问题。
    *   `publish_year`: 一个可选的整数，用于按年份筛选。

#### 1.2. 构建查询生成链 (Query generation)

接下来，我们构建一个不包含任何示例的初始 LangChain 链（Chain）。

```python
# 原文代码
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI

# 系统指令，告诉模型它的角色和任务
system = """You are an expert at converting user questions into database queries. \
You have access to a database of tutorial videos about a software library for building LLM-powered applications. \
Given a question, return a list of database queries optimized to retrieve the most relevant results.

If there are acronyms or words you are not familiar with, do not try to rephrase them."""

# 提示模板
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system),
        MessagesPlaceholder("examples", optional=True), # 为将来的示例预留一个占位符
        ("human", "{question}"),
    ]
)
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
# 让 LLM 能够输出我们定义的 Search 结构
structured_llm = llm.with_structured_output(Search)
# 构建完整的链
query_analyzer = {"question": RunnablePassthrough()} | prompt | structured_llm
```

*   **讲解**:
    *   `system`: 定义了模型的身份——一个数据库查询转换专家。
    *   `ChatPromptTemplate`: 这是我们的提示模板。
        *   `MessagesPlaceholder("examples", optional=True)`: 这是一个关键部分。它在提示中创建了一个名为 `examples` 的占位符。`optional=True` 表示即使我们不提供任何示例，这个提示也能正常工作。
        *   `("human", "{question}")`: 用户的实际问题将在这里被填入。
    *   `structured_llm`: 我们使用 `.with_structured_output(Search)` 将一个普通的 LLM 包装成一个可以保证输出符合 `Search` Pydantic 模型格式的 LLM。
    *   `query_analyzer`: 这是我们的执行链。`RunnablePassthrough()` 会将用户的输入原样传递给 `prompt` 中的 `question` 变量。

#### 1.3. 初次尝试（无示例）

让我们用一个复杂的问题来测试这个没有示例的链。

```python
# 原文代码
query_analyzer.invoke(
    "what's the difference between web voyager and reflection agents? do both use langgraph?"
)
```

**输出**:
```
Search(query='difference between web voyager and reflection agents', sub_queries=['what is web voyager', 'what are reflection agents', 'do both web voyager and reflection agents use langgraph?'], publish_year=None)
```

*   **分析**: 这个结果相当不错。它正确地识别了主查询，并分解出了三个子问题。但是，文档指出，我们可能希望它分解得更彻底，比如将关于 Web Voyager 和 Reflection Agents 的问题分开。

---

### 2. 添加示例并优化提示

为了得到更理想的分解结果，我们现在向提示中添加一些高质量的示例。

#### 2.1. 创建示例

我们创建了一个列表，其中每个元素都是一个包含输入问题和我们期望的“标准答案”（即一个 `Search` 对象）的字典。

```python
# 原文代码
examples = []

question = "What's chat langchain, is it a langchain template?"
query = Search(...)
examples.append({"input": question, "tool_calls": [query]})

question = "How to build multi-agent system and stream intermediate steps from it"
query = Search(...)
examples.append({"input": question, "tool_calls": [query]})

# ... 其他示例
```
*   **讲解**: `tool_calls` 这个键名是特意选择的。因为 OpenAI 的模型是通过一种叫做“工具调用（Tool Calling）”或“函数调用（Function Calling）”的机制来生成结构化数据的。所以，我们的示例也必须模拟这种格式。

#### 2.2. 将示例格式化为消息

OpenAI API 需要一个特定的消息序列来理解 few-shot tool-calling 的示例。我们需要一个辅助函数来将我们上面创建的简单字典转换成这种格式。

```python
# 原文代码
import uuid
from typing import Dict
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage

def tool_example_to_messages(example: Dict) -> List[BaseMessage]:
    messages: List[BaseMessage] = [HumanMessage(content=example["input"])]
    openai_tool_calls = []
    for tool_call in example["tool_calls"]:
        openai_tool_calls.append({
            "id": str(uuid.uuid4()), # 为每个工具调用生成唯一ID
            "type": "function",
            "function": {
                "name": tool_call.__class__.__name__, # 函数名是我们的Pydantic类名 "Search"
                "arguments": tool_call.json(), # 参数是Search对象的JSON表示
            },
        })
    # AI的回应：它决定调用工具
    messages.append(
        AIMessage(content="", additional_kwargs={"tool_calls": openai_tool_calls})
    )
    # 工具的返回：模拟工具调用成功
    tool_outputs = example.get("tool_outputs") or ["You have correctly called this tool."] * len(openai_tool_calls)
    for output, tool_call in zip(tool_outputs, openai_tool_calls):
        messages.append(ToolMessage(content=output, tool_call_id=tool_call["id"]))
    return messages

# 将所有示例转换成消息列表
example_msgs = [msg for ex in examples for msg in tool_example_to_messages(ex)]
```

*   **讲解**: `tool_example_to_messages` 函数的作用是模拟一次完整的“用户提问 -> AI决定调用工具 -> 工具返回结果”的对话流程：
    1.  `HumanMessage`: 用户的原始输入问题。
    2.  `AIMessage`: 模拟 AI 的回复。它的 `content` 是空的，但在 `additional_kwargs` 中包含了它决定调用的工具信息（我们的 `Search` 模型和参数）。
    3.  `ToolMessage`: 模拟工具执行后的返回。这里我们简单地返回一个成功信息。`tool_call_id` 将其与 `AIMessage` 中的调用关联起来。

这个序列完美地向模型展示了：“当用户问这样的问题时，你应该像这样调用 `Search` 工具”。

#### 2.3. 构建并运行带示例的链

现在，我们使用 `.partial()` 方法将格式化好的示例消息列表 `example_msgs` 注入到我们之前创建的提示模板的 `examples` 占位符中。

```python
# 原文代码
query_analyzer_with_examples = (
    {"question": RunnablePassthrough()}
    | prompt.partial(examples=example_msgs) # 在这里注入示例
    | structured_llm
)
```
*   **讲解**: `.partial(examples=example_msgs)` 的作用是预先填充提示模板的一部分。现在，每当 `query_analyzer_with_examples` 被调用时，`example_msgs` 中的所有示例对话都会被插入到系统指令和用户实际问题之间。

#### 2.4. 查看优化后的结果

我们用同样的问题再次调用新的链。

```python
# 原文代码
query_analyzer_with_examples.invoke(
    "what's the difference between web voyager and reflection agents? do both use langgraph?"
)
```

**输出**:
```
Search(query="What's the difference between web voyager and reflection agents? Do both use langgraph?", sub_queries=['What is web voyager', 'What are reflection agents', 'Do web voyager and reflection agents use langgraph?'], publish_year=None)
```
* **注意**: 文档中的输出与代码运行的实际输出可能略有不同，但核心思想是一致的。通过示例，模型现在更倾向于将问题分解得更细。例如，它可能会更稳定地将 "web voyager" 和 "reflection agents" 分解成独立的子查询。

### 总结

通过提供高质量的、格式正确的示例，我们有效地“教会”了 LLM 如何更精确地执行复杂的查询分解任务。这种技术是提示工程（Prompt Engineering）中非常强大的一环，尤其是在处理结构化数据输出时。通过 LangSmith 追踪，你可以清晰地看到这些示例消息是如何被包含在最终发送给模型的完整提示中的。