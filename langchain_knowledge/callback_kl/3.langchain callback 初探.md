我们来详细解读 LangChain 文档中关于**如何以及在哪里附加回调 (Attaching Callbacks)** 的内容。

这部分内容非常关键，因为它解释了 Callback 的**作用域 (Scope)** 和 **优先级 (Priority)**。简单来说，就是“我把 Callback 放在哪里，它会对哪些操作生效？”

---

### 核心思想：不同层级的“监听器”

你可以把附加 Callback 想象成在不同层级设置“监听器”：

1.  **在对象创建时 (Constructor Level)**: 你给一个 LLM 或 Chain 的实例装上一个“永久监听器”。只要这个实例在工作，它的监听器就一直在。
2.  **在单次请求时 (Request Level)**: 你给某一次特定的 `invoke()` 或 `ainvoke()` 调用配一个“临时监听器”。这次调用结束后，监听器就失效了。
3.  **在代码块中 (`with` statement)**: 你用一个 `with` 语句圈定一个范围，所有在这个范围内的 LangChain 调用都会被一个“区域监听器”监听到。
4.  **全局 (Global)**: 设置一个“全局监听器”，监听一切（这是一种高级且不常用的功能）。

下面我们用代码来逐一讲解这些方法。

---

### 准备工作：一个简单的自定义 Handler

为了让效果更清晰，我们先创建一个简单的 Handler，它会在事件发生时打印自己的名字和触发的事件。

```python
from typing import Any, Dict, List
from langchain.callbacks.base import BaseCallbackHandler

class MyCustomHandler(BaseCallbackHandler):
    """一个简单的回调处理器，用于演示。"""
    def __init__(self, name: str) -> None:
        super().__init__()
        self.name = name

    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any) -> Any:
        print(f"[{self.name}] Chain Started with inputs: {inputs}")

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> Any:
        print(f"[{self.name}] Chain Ended with outputs: {outputs}")

# 我们将使用这个 Chain 来进行演示
from langchain_openai import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

llm = OpenAI()
prompt = PromptTemplate.from_template("What is a good name for a company that makes {product}?")
chain = LLMChain(llm=llm, prompt=prompt)
```

---

### 1. 在构造函数中附加 (Constructor Callbacks)

这是最常见的方法。你在创建 LangChain 对象（如 LLM、Chain、Agent）时，通过 `callbacks` 参数直接把处理器实例传进去。

**特点**:
*   **作用域**: 这个 Callback 会绑定到**该对象的整个生命周期**。
*   **行为**: 只要你使用这个对象（或包含了这个对象的更上层对象），它的 Callback 就会被触发。

#### 代码 Demo 讲解

```python
# 创建一个处理器实例
handler1 = MyCustomHandler(name="ConstructorHandler")

# 在创建 LLM 实例时，通过构造函数传入 handler1
# 注意：我们把 handler 传给了底层的 LLM
llm_with_callback = OpenAI(callbacks=[handler1])

# 用这个带回调的 LLM 创建一个新的 Chain
chain_with_constructor_callback = LLMChain(llm=llm_with_callback, prompt=prompt)

"""这是chain的另一种实现方式"""
# chain = prompt | llm
# 
# chain_with_callbacks = chain.with_config(callbacks=callbacks)

# --- 第一次调用 ---
print("--- Running first call ---")
chain_with_constructor_callback.invoke({"product": "colorful socks"})

print("\n" + "="*20 + "\n")

# --- 第二次调用 ---
print("--- Running second call ---")
chain_with_constructor_callback.invoke({"product": "smart watches"})
```

**输出分析**:
你会看到，无论是第一次调用还是第二次调用，`[ConstructorHandler]` 的打印信息都出现了。

```
--- Running first call ---
[ConstructorHandler] Chain Started with inputs: {'product': 'colorful socks'}
[ConstructorHandler] Chain Ended with outputs: {'product': 'colorful socks', 'text': '...'}

====================

--- Running second call ---
[ConstructorHandler] Chain Started with inputs: {'product': 'smart watches'}
[ConstructorHandler] Chain Ended with outputs: {'product': 'smart watches', 'text': '...'}```
```

**何时使用**: 当你想要**持续监控**一个特定对象的所有活动时。最常见的场景是为应用设置一个**全局的日志记录器**。

---


### 2. 在请求中附加 (Request Callbacks)

如果你只想为某一次特定的调用附加回调，可以在调用方法 (`invoke`, `ainvoke` 等) 中通过 `config` 参数传入。

**特点**:
*   **作用域**: **仅对本次调用生效**。
*   **优先级**: **最高**。如果在请求中提供了 Callbacks，它会**覆盖**掉构造函数中设置的 Callbacks。

#### 代码 Demo 讲解

我们将继续使用上面创建的 `chain_with_constructor_callback`，它本身带有一个 `ConstructorHandler`。

```python
# 创建一个新的、只用于单次请求的处理器
handler2 = MyCustomHandler(name="RequestHandler")

# --- 第一次调用 (无特殊配置) ---
# 这次调用应该只触发构造函数里的 handler1
print("--- Running call with constructor handler ---")
chain_with_constructor_callback.invoke({"product": "colorful socks"})

print("\n" + "="*20 + "\n")

# --- 第二次调用 (在 config 中传入新的 handler2) ---
# 这次调用应该只触发请求级别的 handler2，而 handler1 不会被触发！
print("--- Running call with request handler ---")
chain_with_constructor_callback.invoke(
    {"product": "smart watches"},
    config={"callbacks": [handler2]}
)
```

**输出分析**:
注意看，第二次调用的输出中，`ConstructorHandler` 消失了，取而代之的是 `RequestHandler`。

```
--- Running call with constructor handler ---
[ConstructorHandler] Chain Started with inputs: {'product': 'colorful socks'}
[ConstructorHandler] Chain Ended with outputs: {'product': 'colorful socks', 'text': '...'}

====================

--- Running call with request handler ---
[RequestHandler] Chain Started with inputs: {'product': 'smart watches'}
[RequestHandler] Chain Ended with outputs: {'product': 'smart watches', 'text': '...'}
```


**何时使用**:
*   **调试**: 当你发现某个特定的输入导致问题时，可以只为这次调用加上详细的日志。
*   **特定功能**: 比如，在一个聊天应用中，只有当用户点击“流式生成”按钮时，你才为这次请求加上 `StreamingStdOutCallbackHandler`。

---

### 3. 使用 `with` 语句 (Context Manager Callbacks)

这是一种非常 Pythonic 的方式，通常用于一些有明确开始和结束的、临时性的回调任务，比如计算成本。`langchain.callbacks.get_openai_callback` 是最典型的例子。

**特点**:
*   **作用域**: 仅对 `with` 代码块内部的所有 LangChain 调用生效。
*   **行为**: 进入 `with` 代码块时，Callback 被激活；退出代码块时，它自动被移除。它本质上是一种更方便的“请求级别”回调。

#### 代码 Demo 讲解

```python
from langchain.callbacks import get_openai_callback

# 创建一个普通的 chain，它没有任何预设的 callback
chain = LLMChain(llm=OpenAI(), prompt=prompt)

# 使用 with 语句包裹我们的调用
with get_openai_callback() as cb:
    # 在这个代码块内的所有 OpenAI 调用都会被 cb 追踪
    chain.invoke({"product": "ergonomic keyboards"})
    chain.invoke({"product": "noise-cancelling headphones"})

    # 在 with 语句块的外面，cb 就不再活动了
    # 但是 cb 对象本身仍然存在，并保存了追踪到的信息

# 打印 cb 对象，查看它收集到的信息
print(cb)
```

**输出分析**:
在 `with` 语句执行完毕后，打印 `cb` 对象会显示出该代码块内所有 OpenAI 调用的 Token 使用量和预估成本。

```
Tokens Used: 65
	Prompt Tokens: 22
	Completion Tokens: 43
Successful Requests: 2
Total Cost (USD): $0.0013
```

**何时使用**: 最适合用于**计量**和**临时监控**。计算 API 调用成本是它的杀手级应用。你也可以用它来临时开启某个 Handler，来调试一整段复杂的业务逻辑代码。

---

### 优先级总结

LangChain 会按照以下顺序来决定使用哪个 Callback：

1.  **请求级别 (`config={"callbacks": ...}`)**: 优先级最高。如果提供了，则只使用它。
2.  **`with` 语句**: 它作为一种特殊的请求级别回调，在其作用域内拥有最高优先级。
3.  **构造函数级别 (`callbacks=[...]`)**: 如果请求级别没有提供回调，则使用在对象创建时绑定的回调。
4.  **全局级别**: (不常用) 如果以上都没有，则会查找全局配置。

这个优先级系统给了你极大的灵活性，让你可以在需要的时候，精确地控制代码的监控和日志行为。